{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nick11roberts/AutoML-Decathlon-hackathon/blob/main/automl_decathlon_starter_kit_hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoML Decathlon Hackathon Notebook\n",
        "\n",
        "This notebook creates a self-contained environment for you to get a better understanding of how to work with the data, how your methods should be formatted, and how the competition pipeline interfaces with each.\n",
        "\n",
        "There are two main steps of the competition pipeline:\n",
        "\n",
        "\n",
        "1.   Ingestion - the datasets are loaded and the model is created, trained, and used to generate predictions\n",
        "2.   Scoring - the generated predictions and true target outputs are used to calculate the final scores of model on each task. The scores are based on varying loss functions depending on the task, but each is defined such that a *lower* score indicates better performace.\n",
        "\n",
        "7 out of the 10 competition tasks are present in the setup for this notebook, so that .\n",
        "\n",
        "As you look through this notebook, keep in mind that what you mainly need to implement is the `Model` class in `model.py`. We recommend that you first look through each element of the `sample_code_submission` directory and especially the code example `model.py`. There are additional examples in the `simple_baseline_models` directory.\n",
        "\n",
        "A short description of the elements of `sample_code_submission` is below. Further details will be explained as you step through this notebook.\n",
        "\n",
        "\n",
        "1.   `metadata`: not relevant in this notebook environment. Required for official competition submissions through CodaLab; do not remove or edit \n",
        "2.   `tasks_to_run.yaml`: specifies a subset of the tasks to run the method on. If not included, will attempt to run on all 10 tasks.\n",
        "3.   `model.py`: where you will implement your method. It contains the `Model` class which is used in the pipeline, and has 3 mandatory functions: `__init__`, `train`, and `test`.\n",
        "4.    You may also include any other necessary files for your method in the directory along with the 3 elements above. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iBY1ijuwTjvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (1) Setup\n",
        "\n",
        "---\n",
        "\n",
        "Run these cells to set up the code environment and download the data.\n",
        "Do not change or remove any of the existing commands in this section."
      ],
      "metadata": {
        "id": "LMDJPt2rweQ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHx4Tdtyo4DW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484430d2-2a4c-4042-cc95-c5e3342dfa1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'automl_decathlon_starter_kit'...\n",
            "remote: Enumerating objects: 298, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 298 (delta 28), reused 1 (delta 0), pack-reused 240\u001b[K\n",
            "Receiving objects: 100% (298/298), 196.13 KiB | 17.83 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ],
      "source": [
        "# Getting starter kit code\n",
        "!git clone -b hackathon https://github.com/cxxz/automl_decathlon_starter_kit.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting datasets, creates a dev_public directory in the required format\n",
        "%cd automl_decathlon_starter_kit/\n",
        "!wget https://storage.googleapis.com/decathlon_test/dev_public.zip\n",
        "!unzip dev_public.zip\n",
        "!rm dev_public.zip"
      ],
      "metadata": {
        "id": "-oCPVNJMl9y2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43babfe5-ceb9-4942-c7f8-a663a145303c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/automl_decathlon_starter_kit\n",
            "--2022-09-30 16:53:06--  https://storage.googleapis.com/decathlon_test/dev_public.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 74.125.68.128, 74.125.24.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1152556537 (1.1G) [application/x-zip-compressed]\n",
            "Saving to: ‘dev_public.zip’\n",
            "\n",
            "dev_public.zip      100%[===================>]   1.07G  49.2MB/s    in 22s     \n",
            "\n",
            "2022-09-30 16:53:28 (50.3 MB/s) - ‘dev_public.zip’ saved [1152556537/1152556537]\n",
            "\n",
            "Archive:  dev_public.zip\n",
            "   creating: dev_public/md/\n",
            "   creating: dev_public/md/cosmic/\n",
            "  inflating: dev_public/md/cosmic/test_metadata.json  \n",
            "  inflating: dev_public/md/cosmic/train_metadata.json  \n",
            "   creating: dev_public/md/crypto/\n",
            "  inflating: dev_public/md/crypto/test_metadata.json  \n",
            "  inflating: dev_public/md/crypto/train_metadata.json  \n",
            "   creating: dev_public/md/deepsea/\n",
            "  inflating: dev_public/md/deepsea/test_metadata.json  \n",
            "  inflating: dev_public/md/deepsea/train_metadata.json  \n",
            "   creating: dev_public/md/ecg/\n",
            "  inflating: dev_public/md/ecg/test_metadata.json  \n",
            "  inflating: dev_public/md/ecg/train_metadata.json  \n",
            "   creating: dev_public/md/ember/\n",
            "  inflating: dev_public/md/ember/test_metadata.json  \n",
            "  inflating: dev_public/md/ember/train_metadata.json  \n",
            "   creating: dev_public/md/fsd50k/\n",
            "  inflating: dev_public/md/fsd50k/test_metadata.json  \n",
            "  inflating: dev_public/md/fsd50k/train_metadata.json  \n",
            "  inflating: dev_public/md/fsd50k/val_metadata.json  \n",
            "   creating: dev_public/md/navierstokes/\n",
            "  inflating: dev_public/md/navierstokes/test_metadata.json  \n",
            "  inflating: dev_public/md/navierstokes/train_metadata.json  \n",
            "   creating: dev_public/md/ninapro/\n",
            "  inflating: dev_public/md/ninapro/test_metadata.json  \n",
            "  inflating: dev_public/md/ninapro/train_metadata.json  \n",
            "   creating: dev_public/md/nottingham/\n",
            "  inflating: dev_public/md/nottingham/test_metadata.json  \n",
            "  inflating: dev_public/md/nottingham/train_metadata.json  \n",
            "   creating: dev_public/md/spherical/\n",
            "  inflating: dev_public/md/spherical/test_metadata.json  \n",
            "  inflating: dev_public/md/spherical/train_metadata.json  \n",
            "   creating: dev_public/processed_data/\n",
            "   creating: dev_public/processed_data/crypto/\n",
            "  inflating: dev_public/processed_data/crypto/x_test.npy  \n",
            "  inflating: dev_public/processed_data/crypto/x_train.npy  \n",
            "  inflating: dev_public/processed_data/crypto/y_test.npy  \n",
            "  inflating: dev_public/processed_data/crypto/y_train.npy  \n",
            "   creating: dev_public/processed_data/deepsea/\n",
            "  inflating: dev_public/processed_data/deepsea/x_test.npy  \n",
            "  inflating: dev_public/processed_data/deepsea/x_train.npy  \n",
            "  inflating: dev_public/processed_data/deepsea/y_test.npy  \n",
            "  inflating: dev_public/processed_data/deepsea/y_train.npy  \n",
            "   creating: dev_public/processed_data/ember/\n",
            "  inflating: dev_public/processed_data/ember/x_test.npy  \n",
            "  inflating: dev_public/processed_data/ember/x_train.npy  \n",
            "  inflating: dev_public/processed_data/ember/y_test.npy  \n",
            "  inflating: dev_public/processed_data/ember/y_train.npy  \n",
            "   creating: dev_public/processed_data/navierstokes/\n",
            "  inflating: dev_public/processed_data/navierstokes/x_test.npy  \n",
            "  inflating: dev_public/processed_data/navierstokes/x_train.npy  \n",
            "  inflating: dev_public/processed_data/navierstokes/y_test.npy  \n",
            "  inflating: dev_public/processed_data/navierstokes/y_train.npy  \n",
            "   creating: dev_public/processed_data/ninapro/\n",
            "  inflating: dev_public/processed_data/ninapro/x_test.npy  \n",
            "  inflating: dev_public/processed_data/ninapro/x_train.npy  \n",
            "  inflating: dev_public/processed_data/ninapro/y_test.npy  \n",
            "  inflating: dev_public/processed_data/ninapro/y_train.npy  \n",
            "   creating: dev_public/processed_data/nottingham/\n",
            "  inflating: dev_public/processed_data/nottingham/test.npy  \n",
            "  inflating: dev_public/processed_data/nottingham/train.npy  \n",
            "   creating: dev_public/processed_data/spherical/\n",
            "  inflating: dev_public/processed_data/spherical/x_test.npy  \n",
            "  inflating: dev_public/processed_data/spherical/x_train.npy  \n",
            "  inflating: dev_public/processed_data/spherical/y_test.npy  \n",
            "  inflating: dev_public/processed_data/spherical/y_train.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing dependency\n",
        "!pip install xgboost==1.6.1\n",
        "# Feel free to add any others that you may want to use\n"
      ],
      "metadata": {
        "id": "2fFZ3-GHlfJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79005b2-d14b-4b73-c76c-b9017138166d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.6.1\n",
            "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 192.9 MB 71 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.1) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.1) (1.21.6)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (2) Pipeline Toy Examples\n",
        "\n",
        "---\n",
        "\n",
        "This section will walk you through the competition pipeline with descriptions and small segmented examples, only operating on a single task.\n",
        "\n"
      ],
      "metadata": {
        "id": "_ptXGgCZStJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining some variables and copying chosen model directory for testing purposes."
      ],
      "metadata": {
        "id": "Ce2qHR6ccSRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import join\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "'''\n",
        "Choose 1 dataset to run toy examples on. \n",
        "Feel free to change this to any one of the included tasks.\n",
        "'''\n",
        "dataset = 'nottingham'\n",
        "\n",
        "# copy simple model\n",
        "baseline_dir = 'simple_baseline_models/'\n",
        "test_dir = 'test_model'\n",
        "inges_dir = 'ingestion/'\n",
        "score_dir = 'scoring/'  \n",
        "\n",
        "from sys import path\n",
        "path.append(test_dir); path.append(inges_dir); path.append(score_dir); path.append(baseline_dir);\n",
        "\n",
        "'''\n",
        "Choose 1 baseline model to run toy examples with.\n",
        "Feel free to change this to any one of the included baselines, or you can test your own\n",
        "'''\n",
        "model_simple = join(baseline_dir, 'decathlon_xgb', '.') # choose one simple baseline model; change this if needed\n",
        "\n",
        "!mkdir -p $test_dir\n",
        "!cp -r $model_simple $test_dir # copy the model directory"
      ],
      "metadata": {
        "id": "Li3dIIogmp6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2.1) Ingestion; Dataset Loading\n",
        "\n",
        "---\n",
        "\n",
        "The first step of the ingestion process is to load the data. A custom `DecathlonDataset` class, which extends the pytorch `Dataset`, has been implemented within the pipeline. Each instance also holds metadata information, such as the input shape, output shape, number of samples, and task type (single-label classification, multi-label classification, regression). This metadata is passed to the `model`.\n",
        "\n",
        "This is already implemented in the ingestion code, so you do not need to change or add anything.\n"
      ],
      "metadata": {
        "id": "778Gu7Aucabe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dev_datasets import DecathlonDataset, extract_metadata\n",
        "\n",
        "train_dataset = DecathlonDataset(dataset, './dev_public', 'train')\n",
        "test_dataset = DecathlonDataset(dataset, './dev_public', 'test')\n",
        "\n",
        "md_train = extract_metadata(train_dataset)\n",
        "md_test = extract_metadata(test_dataset)\n",
        "print (\"Dataset path: \", md_train.get_dataset_name())\n",
        "print (\"Input shape: \",  md_train.get_tensor_shape())\n",
        "print (\"Output shape:\", md_train.get_output_shape())\n",
        "print (\"Dataset size: \",  md_train.size())"
      ],
      "metadata": {
        "id": "cTpgNG5konYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ee5f7f-9dd8-4c91-b071-e04b9823de4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path:  nottingham\n",
            "Input shape:  (1792, 88, 1, 1)\n",
            "Output shape: (88,)\n",
            "Dataset size:  693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function similar to the one below is already implemented within `Model` class for you to use for training and testing. "
      ],
      "metadata": {
        "id": "9iSSNSiY8vs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "'''\n",
        "A similar function is implemented within the Model class.\n",
        "'''\n",
        "def get_dataloader(dataset, batch_size, split):\n",
        "    \"\"\"Get the PyTorch dataloader.\n",
        "    Args:\n",
        "        dataset:\n",
        "        batch_size : batch_size for training set\n",
        "\n",
        "    Return:\n",
        "        dataloader: PyTorch Dataloader\n",
        "    \"\"\"\n",
        "    if split == \"train\":\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            dataset.required_batch_size or batch_size,\n",
        "            shuffle=True,\n",
        "            drop_last=False,\n",
        "            collate_fn=dataset.collate_fn,\n",
        "        )\n",
        "    elif split == \"test\":\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            dataset.required_batch_size or batch_size,\n",
        "            shuffle=False,\n",
        "            collate_fn=dataset.collate_fn,\n",
        "        )\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "batch_size = 1\n",
        "train_loader = get_dataloader(train_dataset, batch_size, 'train')\n",
        "test_loader = get_dataloader(test_dataset, batch_size, 'test')"
      ],
      "metadata": {
        "id": "9MWNfRn0oxyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing output size\n",
        "labels = []\n",
        "for x, y in test_loader:\n",
        "    if len(labels) < 10:\n",
        "        print(x.shape, y.shape)\n",
        "    label = y.tolist()\n",
        "    labels += label"
      ],
      "metadata": {
        "id": "LRSoiUSuo48C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65807319-14fc-4fd9-ea1e-f01066b13d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n",
            "torch.Size([1, 1792, 88, 1, 1]) torch.Size([1, 88])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2.2) Ingestion; Creating and Training the Model\n",
        "\n",
        "---\n",
        "\n",
        "Within the ingestion process, the metadata of the dataset is used to initialize the `Model` instance. Your implementation of the `Model` class determines how the metadata of the task will affect aspects of your method, such as architecture, size, etc."
      ],
      "metadata": {
        "id": "bUWZbhF1ZlIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# set time budget and instantiate the model\n",
        "from model import Model\n",
        "M = Model(md_train) # pass the metadata of the dataset"
      ],
      "metadata": {
        "id": "FbeQo6JspBJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e248c2b-ede0-4319-b38f-ac13bc329c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Device Found =  cuda \n",
            "Moving Model and Data into the device...\n",
            "\n",
            "\n",
            "INPUT SHAPE =  (88, 1792, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for a certain time budget.\n",
        "\n",
        "The `train` function of the `Model` class takes a `DecathlonDataset` instance for the training data and a `remaining_time_budget` as arguments. Additionally, there may be an optional validation dataset and corresponding metadata passed to `train`, in the case where the task has a special, pre-made validation split. In most cases, however, the validation data is not pre-prepared and you should create your own train/validation splits for model selection within the function.\n",
        "\n",
        "In the cell below, the time budget is purely illustrative. \n",
        "It is passed to the model's mandatory `train` function, where the logic on how it should affect the training process must be implemented, otherwise your method may be at risk of timing out in the true ingestion procedure.\n",
        "\n",
        "This logic is not implemented in the baselines and the following cell has no such time-out function.\n",
        "\n",
        "Again, a reminder that this is already implemented in the ingestion so you do not need to change anything in the starter kit code."
      ],
      "metadata": {
        "id": "jnAOe8FazUOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_budget = 200\n",
        "M.train(train_dataset, val_dataset=None, val_metadata=None, remaining_time_budget=time_budget)"
      ],
      "metadata": {
        "id": "HELMG7RupBtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30d879d-e512-4a5a-94a0-43c78826fa88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(693, 157696) (693, 88)\n",
            "[0]\tvalidation_0-logloss:0.13629\n",
            "[1]\tvalidation_0-logloss:0.05228\n",
            "[2]\tvalidation_0-logloss:0.02623\n",
            "[3]\tvalidation_0-logloss:0.01772\n",
            "[4]\tvalidation_0-logloss:0.01516\n",
            "[5]\tvalidation_0-logloss:0.01415\n",
            "[6]\tvalidation_0-logloss:0.01418\n",
            "[7]\tvalidation_0-logloss:0.01448\n",
            "[8]\tvalidation_0-logloss:0.01476\n",
            "[9]\tvalidation_0-logloss:0.01497\n",
            "[10]\tvalidation_0-logloss:0.01517\n",
            "2022-09-30 16:57:02,352 INFO model.py: 135.02 sec used for xgboost. Total time used for training: 135.02 sec. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2.) Testing and Scoring the Model"
      ],
      "metadata": {
        "id": "ZhzVQ6SUZsSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing is still a part of the ingestion process. The model's mandatory`test` method is called to generate and save the predictions on the test dataset.\n",
        "\n",
        "The `time_budget` is the time remaining after `train` and passed to the model's mandatory `test` function, but is not utilized for the baselines or cell examples. During a local test or actual submission, it is important to note that the time required for testing is part of the overall time budget, so your method should leave enough time for generating predictions."
      ],
      "metadata": {
        "id": "p2iSBaXvw7nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get prediction by calling test method\n",
        "prediction = M.test(test_dataset, remaining_time_budget=time_budget)\n",
        "print(prediction.shape)\n",
        "print(prediction[0])"
      ],
      "metadata": {
        "id": "Lfx_6wUPpBzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0c9b73-a6db-4e50-ff7e-0383004cce09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-30 16:57:09,920 INFO model.py: Begin testing...\n",
            "2022-09-30 16:57:10,297 INFO model.py: [+] Successfully made one prediction. 0.38 sec used. Total time used for testing: 0.38 sec. \n",
            "(174, 88)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the scoring process (which follows the entire ingestion process), the saved predictions and true outputs are read, then used to calculate the score per task. The tasks' score types differ - for example, one may be based on AUROC while another is based on negative log likelihood loss - but they are all defined such that **a lower score indicates better performance**. "
      ],
      "metadata": {
        "id": "-_KyR6cIxKfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Quick test of get_solution from score.py\n",
        "''' \n",
        "\n",
        "from score import get_solution\n",
        "\n",
        "solution = get_solution(\"dev_public\", dataset)\n",
        "print(solution.shape)\n",
        "print(solution)"
      ],
      "metadata": {
        "id": "KJmd5xNtoulb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c6bd5f-ca58-4a22-b6b9-247724dce665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-30 16:57:18,719 INFO score.py: solution shape=(174, 88)\n",
            "(174, 88)\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from score import decathlon_scorer\n",
        "\n",
        "score = decathlon_scorer(solution, prediction, dataset)\n",
        "print (\"Score: \", score)"
      ],
      "metadata": {
        "id": "1FA4YwgbpGx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fede41-8c0f-4a9f-c5c8-26d9ae6b54b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score:  0.26123303174972534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once your method has a score on all 10 tasks, these task scores are compared with other submissions and baselines to determine the final AUP metric. We will not calculate any AUPs in this notebook since it is by definition a relative metric that depends on other submissions, but if you are interested to know more you can visit the CodaLab page where details are provided."
      ],
      "metadata": {
        "id": "LaTxh6rl_ddN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) Pipeline Local Test\n",
        "\n",
        "The command below simulates a run of the selected model through the ingestion and scoring processes. Use this to check your own method's results, and make sure the arguments are properly specified.\n",
        "\n",
        "Datasets can be specified in `tasks_to_run.yaml` in the model directory. \n",
        "\n",
        "For this local test, it is recommended you always include this file; otherwise, it will attempt to run all 10 tasks which will clutter the output. We recommend you start with one or two of the smallest tasks and work you way up to the subset provided for the hackathon.\n",
        "\n",
        "The printed output will contain both the ingestion logs and scoring logs for use in debugging. The `model.py` file you implement should contain a logger which you can use to output desired information to the ingestion log. \n",
        "\n",
        "In this case the `time_budget` (in seconds) argument matters, so make sure you set it to a reasonable value for your experiments, otherwise the ingestion will think you have timed out and give you bad scores for the tasks."
      ],
      "metadata": {
        "id": "V4h0aHgyUCJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_local_test.py --code_dir=./test_model --dataset_dir=./dev_public --time_budget=2000"
      ],
      "metadata": {
        "id": "NsWGsFiat3kV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29119bc-a154-45cd-9400-c27517559fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-30 16:57:41 INFO run_local_test.py: ##################################################\n",
            "2022-09-30 16:57:41 INFO run_local_test.py: Begin running local test using\n",
            "2022-09-30 16:57:41 INFO run_local_test.py: code_dir = test_model\n",
            "2022-09-30 16:57:41 INFO run_local_test.py: dataset_dir = dev_public\n",
            "2022-09-30 16:57:41 INFO run_local_test.py: ##################################################\n",
            "2022-09-30 16:57:43,775 INFO ingestion.py: Found user-specified task list: navierstokes spherical ninapro deepsea nottingham crypto ember\n",
            "2022-09-30 16:57:43,775 INFO ingestion.py: Starting ingestion for navierstokes\n",
            "2022-09-30 16:57:43,776 INFO ingestion.py: Starting ingestion for navierstokes, this has a time constraint of 2000.0 s.\n",
            "2022-09-30 16:57:43,776 INFO ingestion.py: ************************************************\n",
            "2022-09-30 16:57:43,776 INFO ingestion.py: ******** Processing dataset Navierstokes ********\n",
            "2022-09-30 16:57:43,776 INFO ingestion.py: ************************************************\n",
            "2022-09-30 16:57:43,776 INFO ingestion.py: Reading navierstokes training set and test set...\n",
            "2022-09-30 16:57:44,141 INFO ingestion.py: Created training and test datasets\n",
            "2022-09-30 16:57:44,141 INFO ingestion.py: Creating model...\n",
            "Device Found =  cuda \n",
            "Moving Model and Data into the device...\n",
            "\n",
            "\n",
            "INPUT SHAPE =  (1, 20, 64, 64)\n",
            "2022-09-30 16:57:44,173 INFO ingestion.py: ===== Start core part of ingestion program. Version: v20220707 =====\n",
            "2022-09-30 16:57:44,173 INFO ingestion.py: Begin training the model...\n",
            "(864, 81920) (864, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RygkZpC2VRMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}